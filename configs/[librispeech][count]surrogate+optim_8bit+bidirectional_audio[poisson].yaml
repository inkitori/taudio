# Base experiment configuration
experiment_name: "[librispeech][count]surrogate+optim_8bit+bidirectional_audio[poisson]"
description: "Surrogate loss, 8-bit optimizer, bidirectional audio, poisson loss"

# Model configuration
model:
  model_id: "Qwen/Qwen2.5-Omni-3B"
  load_in_8bit: false
  freeze_text_model: false
  audio_layer: -1
  bidirectional_audio: true
  linear_bias: -3

# Training configuration
training:
  epochs: 100
  batch_size: 1
  grad_accumulation_steps: 8
  learning_rate: 5.0e-6
  eta_min_scale: 0.1
  optim_8bit: true
  
# Dataset configuration
dataset:
  split: "train_clean_100"
  repository: "gilkeyio/librispeech-alignments"
  task: "SPEAKER_COUNTING"
  padding: 0
  # take_first: 8
  
# Loss configuration
loss:
  class_weighting: false
  surrogate_loss: true
  token_loss: true
  surrogate_loss_weight: 0.05
  poisson_loss: true

# System configuration
system:
  dataloader_num_workers: 1
  seed: 80
  save_checkpoints: false

# Wandb configuration
wandb:
  entity: "taudio"
  project: "Train"
  tags: ["surrogate", "optim_8bit", "bidirectional_audio", "speaker_counting", "padding_0", "poisson"] 