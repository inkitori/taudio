# High learning rate experiment configuration
experiment_name: "high_lr_experiment"
description: "Experiment with higher learning rate and frozen text model"

# Model configuration
model:
  model_id: "Qwen/Qwen2.5-Omni-3B"
  load_in_8bit: false
  freeze_text_model: true  # freeze text model for stability
  audio_layer: 18

# Training configuration
training:
  epochs: 2
  batch_size: 2
  grad_accumulation_steps: 4
  learning_rate: 1e-5  # higher learning rate
  eta_min_scale: 0.05
  optim_8bit: true
  
# Dataset configuration
dataset:
  split: "train_clean_100"
  key: "start"
  
# Loss configuration
loss:
  class_weighting: false  # disable class weighting
  surrogate_loss: true
  token_loss: false  # only surrogate loss
  surrogate_loss_weight: 1.0

# System configuration
system:
  dataloader_num_workers: 8
  seed: 80

# Wandb configuration
wandb:
  entity: "taudio"
  project: "Train"
  tags: ["high_lr", "frozen_text", "experiment"] 