{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "28814a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "\n",
    "from transformers import Qwen2_5OmniThinkerForConditionalGeneration, Qwen2_5OmniProcessor\n",
    "from qwen_omni_utils import process_mm_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63f2a721",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section'}\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00,  6.03it/s]\n"
     ]
    }
   ],
   "source": [
    "model_id = \"Qwen/Qwen2.5-Omni-3B\"\n",
    "model = Qwen2_5OmniThinkerForConditionalGeneration.from_pretrained(model_id, torch_dtype=\"auto\", device_map=\"auto\")\n",
    "processor = Qwen2_5OmniProcessor.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bfcb3307",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = [\n",
    "    # {\n",
    "    #     \"role\": \"system\",\n",
    "    #     \"content\": [\n",
    "    #         {\"type\": \"text\", \"text\": \"You are Qwen, a virtual human developed by the Qwen Team, Alibaba Group, capable of perceiving auditory and visual inputs, as well as generating text and speech.\"}\n",
    "    #     ],\n",
    "    # },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"audio\", \"audio\": \"data/datasets/LibriSpeech/LibriSpeech/test-clean/61/70968/61-70968-0000.flac\"},\n",
    "        ],\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "59ddea9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:System prompt modified, audio output may not work as expected. Audio output mode only works when using default system prompt 'You are Qwen, a virtual human developed by the Qwen Team, Alibaba Group, capable of perceiving auditory and visual inputs, as well as generating text and speech.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text input for the model:\n",
      "['<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n<|im_start|>user\\n<|audio_bos|><|AUDIO|><|audio_eos|><|im_end|>\\n<|im_start|>assistant\\n']\n",
      "Audio, Image, and Video inputs for the model:\n",
      "Audios:\n",
      "[array([-9.3078613e-03, -9.6130371e-03, -9.0637207e-03, ...,\n",
      "        4.1198730e-03,  2.3803711e-03, -6.1035156e-05], dtype=float32)]\n",
      "(78480,)\n",
      "Images:\n",
      "None\n",
      "Videos:\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "USE_AUDIO_IN_VIDEO = True\n",
    "\n",
    "# Preparation for inference\n",
    "text = processor.apply_chat_template(conversation, add_generation_prompt=True, tokenize=False)\n",
    "print(\"Text input for the model:\")\n",
    "print(text)\n",
    "audios, images, videos = process_mm_info(conversation, use_audio_in_video=USE_AUDIO_IN_VIDEO)\n",
    "\n",
    "print(\"Audio, Image, and Video inputs for the model:\")\n",
    "print(\"Audios:\")\n",
    "print(audios);\n",
    "print(audios[0].shape)\n",
    "\n",
    "print(\"Images:\")\n",
    "print(images)\n",
    "\n",
    "print(\"Videos:\")\n",
    "print(videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "edb27090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed inputs for the model:\n",
      "491\n",
      "torch.Size([1, 128, 30000])\n"
     ]
    }
   ],
   "source": [
    "inputs = processor(text=text, audio=audios, images=images, videos=videos, return_tensors=\"pt\", padding=True, use_audio_in_video=USE_AUDIO_IN_VIDEO)\n",
    "print(\"Processed inputs for the model:\")\n",
    "cnt = 0\n",
    "for i in inputs.feature_attention_mask[0]:\n",
    "\tif i == 1:\n",
    "\t\tcnt += 1\n",
    "\n",
    "inputs = inputs.to(model.device).to(model.dtype)\n",
    "\n",
    "print(cnt)\n",
    "print(inputs.input_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "92fcd501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([123, 2048])\n"
     ]
    }
   ],
   "source": [
    "audio_features = model.get_audio_features(\n",
    "\tinputs.input_features,\n",
    "\tfeature_attention_mask=inputs.feature_attention_mask,\n",
    ")\n",
    "print(audio_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9d742ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(**inputs, output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "91977494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 144, 2048])\n"
     ]
    }
   ],
   "source": [
    "inputs_embeds = model.get_input_embeddings()(inputs.input_ids)\n",
    "print(inputs_embeds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1357f308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n<|im_start|>user\\n<|audio_bos|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|AUDIO|><|audio_eos|><|im_end|>\\n<|im_start|>assistant\\n']\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "print(tokenizer.batch_decode(inputs.input_ids, skip_special_tokens=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "efeb4cb6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Inference: Generation of the output text and audio\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m text_ids, audio = model.generate(**inputs, use_audio_in_video=USE_AUDIO_IN_VIDEO)\n\u001b[32m      4\u001b[39m text = processor.batch_decode(text_ids, skip_special_tokens=\u001b[38;5;28;01mTrue\u001b[39;00m, clean_up_tokenization_spaces=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(text)\n",
      "\u001b[31mValueError\u001b[39m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "# Inference: Generation of the output text and audio\n",
    "text_ids, audio = model.generate(**inputs, use_audio_in_video=USE_AUDIO_IN_VIDEO)\n",
    "\n",
    "text = processor.batch_decode(text_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "print(text)\n",
    "sf.write(\n",
    "    \"output.wav\",\n",
    "    audio.reshape(-1).detach().cpu().numpy(),\n",
    "    samplerate=24000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92b57002",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "296717da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 338M/338M [00:26<00:00, 12.9MB/s] \n",
      "Downloading data: 100%|██████████| 314M/314M [00:58<00:00, 5.38MB/s] \n",
      "Downloading data: 100%|██████████| 347M/347M [01:24<00:00, 4.10MB/s] \n",
      "Downloading data: 100%|██████████| 329M/329M [01:01<00:00, 5.32MB/s] \n",
      "Downloading data:  17%|█▋        | 1.07G/6.39G [05:00<32:54, 2.70MB/s]  "
     ]
    },
    {
     "ename": "FSTimeoutError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCancelledError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/gscratch/ark/anjo0/miniconda3/envs/taudio/lib/python3.12/site-packages/aiohttp/streams.py:347\u001b[39m, in \u001b[36mStreamReader._wait\u001b[39m\u001b[34m(self, func_name)\u001b[39m\n\u001b[32m    346\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._timer:\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m waiter\n\u001b[32m    348\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[31mCancelledError\u001b[39m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mTimeoutError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/gscratch/ark/anjo0/miniconda3/envs/taudio/lib/python3.12/site-packages/fsspec/asyn.py:56\u001b[39m, in \u001b[36m_runner\u001b[39m\u001b[34m(event, coro, result, timeout)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     result[\u001b[32m0\u001b[39m] = \u001b[38;5;28;01mawait\u001b[39;00m coro\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gscratch/ark/anjo0/miniconda3/envs/taudio/lib/python3.12/site-packages/fsspec/implementations/http.py:262\u001b[39m, in \u001b[36mHTTPFileSystem._get_file\u001b[39m\u001b[34m(self, rpath, lpath, chunk_size, callback, **kwargs)\u001b[39m\n\u001b[32m    261\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m chunk:\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m     chunk = \u001b[38;5;28;01mawait\u001b[39;00m r.content.read(chunk_size)\n\u001b[32m    263\u001b[39m     outfile.write(chunk)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gscratch/ark/anjo0/miniconda3/envs/taudio/lib/python3.12/site-packages/aiohttp/streams.py:428\u001b[39m, in \u001b[36mStreamReader.read\u001b[39m\u001b[34m(self, n)\u001b[39m\n\u001b[32m    427\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._buffer \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._eof:\n\u001b[32m--> \u001b[39m\u001b[32m428\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._wait(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    430\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._read_nowait(n)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gscratch/ark/anjo0/miniconda3/envs/taudio/lib/python3.12/site-packages/aiohttp/streams.py:346\u001b[39m, in \u001b[36mStreamReader._wait\u001b[39m\u001b[34m(self, func_name)\u001b[39m\n\u001b[32m    345\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._timer:\n\u001b[32m    347\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m waiter\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gscratch/ark/anjo0/miniconda3/envs/taudio/lib/python3.12/site-packages/aiohttp/helpers.py:685\u001b[39m, in \u001b[36mTimerContext.__exit__\u001b[39m\u001b[34m(self, exc_type, exc_val, exc_tb)\u001b[39m\n\u001b[32m    684\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m685\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m asyncio.TimeoutError \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc_val\u001b[39;00m\n\u001b[32m    686\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mTimeoutError\u001b[39m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mFSTimeoutError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# load openslr/librispeech_asr\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m librispeech_asr = datasets.load_dataset(\u001b[33m\"\u001b[39m\u001b[33mopenslr/librispeech_asr\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gscratch/ark/anjo0/miniconda3/envs/taudio/lib/python3.12/site-packages/datasets/load.py:2084\u001b[39m, in \u001b[36mload_dataset\u001b[39m\u001b[34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, keep_in_memory, save_infos, revision, token, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001b[39m\n\u001b[32m   2081\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m builder_instance.as_streaming_dataset(split=split)\n\u001b[32m   2083\u001b[39m \u001b[38;5;66;03m# Download and prepare data\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2084\u001b[39m builder_instance.download_and_prepare(\n\u001b[32m   2085\u001b[39m     download_config=download_config,\n\u001b[32m   2086\u001b[39m     download_mode=download_mode,\n\u001b[32m   2087\u001b[39m     verification_mode=verification_mode,\n\u001b[32m   2088\u001b[39m     num_proc=num_proc,\n\u001b[32m   2089\u001b[39m     storage_options=storage_options,\n\u001b[32m   2090\u001b[39m )\n\u001b[32m   2092\u001b[39m \u001b[38;5;66;03m# Build dataset for splits\u001b[39;00m\n\u001b[32m   2093\u001b[39m keep_in_memory = (\n\u001b[32m   2094\u001b[39m     keep_in_memory \u001b[38;5;28;01mif\u001b[39;00m keep_in_memory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m is_small_dataset(builder_instance.info.dataset_size)\n\u001b[32m   2095\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gscratch/ark/anjo0/miniconda3/envs/taudio/lib/python3.12/site-packages/datasets/builder.py:925\u001b[39m, in \u001b[36mDatasetBuilder.download_and_prepare\u001b[39m\u001b[34m(self, output_dir, download_config, download_mode, verification_mode, dl_manager, base_path, file_format, max_shard_size, num_proc, storage_options, **download_and_prepare_kwargs)\u001b[39m\n\u001b[32m    923\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m num_proc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    924\u001b[39m     prepare_split_kwargs[\u001b[33m\"\u001b[39m\u001b[33mnum_proc\u001b[39m\u001b[33m\"\u001b[39m] = num_proc\n\u001b[32m--> \u001b[39m\u001b[32m925\u001b[39m \u001b[38;5;28mself\u001b[39m._download_and_prepare(\n\u001b[32m    926\u001b[39m     dl_manager=dl_manager,\n\u001b[32m    927\u001b[39m     verification_mode=verification_mode,\n\u001b[32m    928\u001b[39m     **prepare_split_kwargs,\n\u001b[32m    929\u001b[39m     **download_and_prepare_kwargs,\n\u001b[32m    930\u001b[39m )\n\u001b[32m    931\u001b[39m \u001b[38;5;66;03m# Sync info\u001b[39;00m\n\u001b[32m    932\u001b[39m \u001b[38;5;28mself\u001b[39m.info.dataset_size = \u001b[38;5;28msum\u001b[39m(split.num_bytes \u001b[38;5;28;01mfor\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.info.splits.values())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gscratch/ark/anjo0/miniconda3/envs/taudio/lib/python3.12/site-packages/datasets/builder.py:1649\u001b[39m, in \u001b[36mGeneratorBasedBuilder._download_and_prepare\u001b[39m\u001b[34m(self, dl_manager, verification_mode, **prepare_splits_kwargs)\u001b[39m\n\u001b[32m   1648\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_download_and_prepare\u001b[39m(\u001b[38;5;28mself\u001b[39m, dl_manager, verification_mode, **prepare_splits_kwargs):\n\u001b[32m-> \u001b[39m\u001b[32m1649\u001b[39m     \u001b[38;5;28msuper\u001b[39m()._download_and_prepare(\n\u001b[32m   1650\u001b[39m         dl_manager,\n\u001b[32m   1651\u001b[39m         verification_mode,\n\u001b[32m   1652\u001b[39m         check_duplicate_keys=verification_mode == VerificationMode.BASIC_CHECKS\n\u001b[32m   1653\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m verification_mode == VerificationMode.ALL_CHECKS,\n\u001b[32m   1654\u001b[39m         **prepare_splits_kwargs,\n\u001b[32m   1655\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gscratch/ark/anjo0/miniconda3/envs/taudio/lib/python3.12/site-packages/datasets/builder.py:979\u001b[39m, in \u001b[36mDatasetBuilder._download_and_prepare\u001b[39m\u001b[34m(self, dl_manager, verification_mode, **prepare_split_kwargs)\u001b[39m\n\u001b[32m    977\u001b[39m split_dict = SplitDict(dataset_name=\u001b[38;5;28mself\u001b[39m.dataset_name)\n\u001b[32m    978\u001b[39m split_generators_kwargs = \u001b[38;5;28mself\u001b[39m._make_split_generators_kwargs(prepare_split_kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m split_generators = \u001b[38;5;28mself\u001b[39m._split_generators(dl_manager, **split_generators_kwargs)\n\u001b[32m    981\u001b[39m \u001b[38;5;66;03m# Checksums verification\u001b[39;00m\n\u001b[32m    982\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m verification_mode == VerificationMode.ALL_CHECKS \u001b[38;5;129;01mand\u001b[39;00m dl_manager.record_checksums:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gscratch/ark/anjo0/taudio/.cache/huggingface/modules/datasets_modules/datasets/openslr--librispeech_asr/2712a8f82f0d20807a56faadcd08734f9bdd24c850bb118ba21ff33ebff0432f/librispeech_asr.py:115\u001b[39m, in \u001b[36mLibrispeechASR._split_generators\u001b[39m\u001b[34m(self, dl_manager)\u001b[39m\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_split_generators\u001b[39m(\u001b[38;5;28mself\u001b[39m, dl_manager):\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     archive_path = dl_manager.download(_DL_URLS[\u001b[38;5;28mself\u001b[39m.config.name])\n\u001b[32m    116\u001b[39m     \u001b[38;5;66;03m# (Optional) In non-streaming mode, we can extract the archive locally to have actual local audio files:\u001b[39;00m\n\u001b[32m    117\u001b[39m     local_extracted_archive = dl_manager.extract(archive_path) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dl_manager.is_streaming \u001b[38;5;28;01melse\u001b[39;00m {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gscratch/ark/anjo0/miniconda3/envs/taudio/lib/python3.12/site-packages/datasets/download/download_manager.py:159\u001b[39m, in \u001b[36mDownloadManager.download\u001b[39m\u001b[34m(self, url_or_urls)\u001b[39m\n\u001b[32m    157\u001b[39m start_time = datetime.now()\n\u001b[32m    158\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m stack_multiprocessing_download_progress_bars():\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m     downloaded_path_or_paths = map_nested(\n\u001b[32m    160\u001b[39m         download_func,\n\u001b[32m    161\u001b[39m         url_or_urls,\n\u001b[32m    162\u001b[39m         map_tuple=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    163\u001b[39m         num_proc=download_config.num_proc,\n\u001b[32m    164\u001b[39m         desc=\u001b[33m\"\u001b[39m\u001b[33mDownloading data files\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    165\u001b[39m         batched=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    166\u001b[39m         batch_size=-\u001b[32m1\u001b[39m,\n\u001b[32m    167\u001b[39m     )\n\u001b[32m    168\u001b[39m duration = datetime.now() - start_time\n\u001b[32m    169\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDownloading took \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mduration.total_seconds()\u001b[38;5;250m \u001b[39m//\u001b[38;5;250m \u001b[39m\u001b[32m60\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m min\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gscratch/ark/anjo0/miniconda3/envs/taudio/lib/python3.12/site-packages/datasets/utils/py_utils.py:522\u001b[39m, in \u001b[36mmap_nested\u001b[39m\u001b[34m(function, data_struct, dict_only, map_list, map_tuple, map_numpy, num_proc, parallel_min_length, batched, batch_size, types, disable_tqdm, desc)\u001b[39m\n\u001b[32m    519\u001b[39m         batch_size = \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mlen\u001b[39m(iterable) // num_proc + \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(iterable) % num_proc > \u001b[32m0\u001b[39m), \u001b[32m1\u001b[39m)\n\u001b[32m    520\u001b[39m     iterable = \u001b[38;5;28mlist\u001b[39m(iter_batched(iterable, batch_size))\n\u001b[32m    521\u001b[39m mapped = [\n\u001b[32m--> \u001b[39m\u001b[32m522\u001b[39m     _single_map_nested((function, obj, batched, batch_size, types, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    523\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m hf_tqdm(iterable, disable=disable_tqdm, desc=desc)\n\u001b[32m    524\u001b[39m ]\n\u001b[32m    525\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m batched:\n\u001b[32m    526\u001b[39m     mapped = [mapped_item \u001b[38;5;28;01mfor\u001b[39;00m mapped_batch \u001b[38;5;129;01min\u001b[39;00m mapped \u001b[38;5;28;01mfor\u001b[39;00m mapped_item \u001b[38;5;129;01min\u001b[39;00m mapped_batch]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gscratch/ark/anjo0/miniconda3/envs/taudio/lib/python3.12/site-packages/datasets/utils/py_utils.py:390\u001b[39m, in \u001b[36m_single_map_nested\u001b[39m\u001b[34m(args)\u001b[39m\n\u001b[32m    383\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m function(data_struct)\n\u001b[32m    384\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    385\u001b[39m     batched\n\u001b[32m    386\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_struct, \u001b[38;5;28mdict\u001b[39m)\n\u001b[32m    387\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_struct, types)\n\u001b[32m    388\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, (\u001b[38;5;28mdict\u001b[39m, types)) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m data_struct)\n\u001b[32m    389\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m390\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [mapped_item \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m iter_batched(data_struct, batch_size) \u001b[38;5;28;01mfor\u001b[39;00m mapped_item \u001b[38;5;129;01min\u001b[39;00m function(batch)]\n\u001b[32m    392\u001b[39m \u001b[38;5;66;03m# Reduce logging to keep things readable in multiprocessing with tqdm\u001b[39;00m\n\u001b[32m    393\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m rank \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m logging.get_verbosity() < logging.WARNING:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gscratch/ark/anjo0/miniconda3/envs/taudio/lib/python3.12/site-packages/datasets/download/download_manager.py:220\u001b[39m, in \u001b[36mDownloadManager._download_batched\u001b[39m\u001b[34m(self, url_or_filenames, download_config)\u001b[39m\n\u001b[32m    206\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m thread_map(\n\u001b[32m    207\u001b[39m         download_func,\n\u001b[32m    208\u001b[39m         url_or_filenames,\n\u001b[32m   (...)\u001b[39m\u001b[32m    216\u001b[39m         tqdm_class=tqdm,\n\u001b[32m    217\u001b[39m     )\n\u001b[32m    218\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    219\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m         \u001b[38;5;28mself\u001b[39m._download_single(url_or_filename, download_config=download_config)\n\u001b[32m    221\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m url_or_filename \u001b[38;5;129;01min\u001b[39;00m url_or_filenames\n\u001b[32m    222\u001b[39m     ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gscratch/ark/anjo0/miniconda3/envs/taudio/lib/python3.12/site-packages/datasets/download/download_manager.py:229\u001b[39m, in \u001b[36mDownloadManager._download_single\u001b[39m\u001b[34m(self, url_or_filename, download_config)\u001b[39m\n\u001b[32m    226\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_relative_path(url_or_filename):\n\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# append the relative path to the base_path\u001b[39;00m\n\u001b[32m    228\u001b[39m     url_or_filename = url_or_path_join(\u001b[38;5;28mself\u001b[39m._base_path, url_or_filename)\n\u001b[32m--> \u001b[39m\u001b[32m229\u001b[39m out = cached_path(url_or_filename, download_config=download_config)\n\u001b[32m    230\u001b[39m out = tracked_str(out)\n\u001b[32m    231\u001b[39m out.set_origin(url_or_filename)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gscratch/ark/anjo0/miniconda3/envs/taudio/lib/python3.12/site-packages/datasets/utils/file_utils.py:214\u001b[39m, in \u001b[36mcached_path\u001b[39m\u001b[34m(url_or_filename, download_config, **download_kwargs)\u001b[39m\n\u001b[32m    211\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    212\u001b[39m     \u001b[38;5;66;03m# Download external files\u001b[39;00m\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m         output_path = get_from_cache(\n\u001b[32m    215\u001b[39m             url_or_filename,\n\u001b[32m    216\u001b[39m             cache_dir=cache_dir,\n\u001b[32m    217\u001b[39m             force_download=download_config.force_download,\n\u001b[32m    218\u001b[39m             user_agent=download_config.user_agent,\n\u001b[32m    219\u001b[39m             use_etag=download_config.use_etag,\n\u001b[32m    220\u001b[39m             token=download_config.token,\n\u001b[32m    221\u001b[39m             storage_options=storage_options,\n\u001b[32m    222\u001b[39m             download_desc=download_config.download_desc,\n\u001b[32m    223\u001b[39m             disable_tqdm=download_config.disable_tqdm,\n\u001b[32m    224\u001b[39m         )\n\u001b[32m    225\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m os.path.exists(url_or_filename):\n\u001b[32m    226\u001b[39m     \u001b[38;5;66;03m# File, and it exists.\u001b[39;00m\n\u001b[32m    227\u001b[39m     output_path = url_or_filename\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gscratch/ark/anjo0/miniconda3/envs/taudio/lib/python3.12/site-packages/datasets/utils/file_utils.py:415\u001b[39m, in \u001b[36mget_from_cache\u001b[39m\u001b[34m(url, cache_dir, force_download, user_agent, use_etag, token, storage_options, download_desc, disable_tqdm)\u001b[39m\n\u001b[32m    413\u001b[39m     logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not found in cache or force_download set to True, downloading to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtemp_file.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    414\u001b[39m     \u001b[38;5;66;03m# GET file object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m415\u001b[39m     fsspec_get(url, temp_file, storage_options=storage_options, desc=download_desc, disable_tqdm=disable_tqdm)\n\u001b[32m    417\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mstoring \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m in cache at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcache_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    418\u001b[39m shutil.move(temp_file.name, cache_path)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gscratch/ark/anjo0/miniconda3/envs/taudio/lib/python3.12/site-packages/datasets/utils/file_utils.py:339\u001b[39m, in \u001b[36mfsspec_get\u001b[39m\u001b[34m(url, temp_file, storage_options, desc, disable_tqdm)\u001b[39m\n\u001b[32m    326\u001b[39m fs, path = url_to_fs(url, **(storage_options \u001b[38;5;129;01mor\u001b[39;00m {}))\n\u001b[32m    327\u001b[39m callback = TqdmCallback(\n\u001b[32m    328\u001b[39m     tqdm_kwargs={\n\u001b[32m    329\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mdesc\u001b[39m\u001b[33m\"\u001b[39m: desc \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mDownloading\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    337\u001b[39m     }\n\u001b[32m    338\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m339\u001b[39m fs.get_file(path, temp_file.name, callback=callback)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gscratch/ark/anjo0/miniconda3/envs/taudio/lib/python3.12/site-packages/fsspec/asyn.py:118\u001b[39m, in \u001b[36msync_wrapper.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m    117\u001b[39m     \u001b[38;5;28mself\u001b[39m = obj \u001b[38;5;129;01mor\u001b[39;00m args[\u001b[32m0\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m sync(\u001b[38;5;28mself\u001b[39m.loop, func, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/gscratch/ark/anjo0/miniconda3/envs/taudio/lib/python3.12/site-packages/fsspec/asyn.py:101\u001b[39m, in \u001b[36msync\u001b[39m\u001b[34m(loop, func, timeout, *args, **kwargs)\u001b[39m\n\u001b[32m     98\u001b[39m return_result = result[\u001b[32m0\u001b[39m]\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(return_result, asyncio.TimeoutError):\n\u001b[32m    100\u001b[39m     \u001b[38;5;66;03m# suppress asyncio.TimeoutError, raise FSTimeoutError\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m FSTimeoutError \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mreturn_result\u001b[39;00m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(return_result, \u001b[38;5;167;01mBaseException\u001b[39;00m):\n\u001b[32m    103\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m return_result\n",
      "\u001b[31mFSTimeoutError\u001b[39m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data:  17%|█▋        | 1.07G/6.39G [05:18<32:54, 2.70MB/s]"
     ]
    }
   ],
   "source": [
    "# load openslr/librispeech_asr\n",
    "\n",
    "librispeech_asr = datasets.load_dataset(\"openslr/librispeech_asr\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "taudio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
